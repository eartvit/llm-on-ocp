{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ded8507-6f19-4271-b43e-21cf44ab5fae",
   "metadata": {},
   "source": [
    "### Set the Inference server url (replace with your own address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e834566-4cc1-4c94-ba2e-821b9b229892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server_url = \"https://mistral-7b-instruct-ollama-test.apps.cluster-d975k.d975k.sandbox3026.opentlc.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca6eda-4709-4d85-bcab-6dc50b20314e",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eba5d7d-10ce-432d-adcc-80458ff26efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain==0.1.9 openai==1.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8839391-a097-4dbc-9a09-b7110a69cabe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install pyOpenSSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae332835-0724-4719-a1f2-80fdec7b03b2",
   "metadata": {},
   "source": [
    "### Extract self signed SSL certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a63b80-fc65-4ab9-9b5e-c89eae7bdb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import OpenSSL\n",
    "import socket\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def save_srv_cert(host, port=443) :\n",
    "    dst = (host, port)\n",
    "    sock = socket.create_connection(dst)\n",
    "    context = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n",
    "    connection = OpenSSL.SSL.Connection(context, sock)\n",
    "    connection.set_tlsext_host_name(host.encode('utf-8'))\n",
    "    connection.set_connect_state()\n",
    "    try:\n",
    "        connection.do_handshake()\n",
    "        certificate = connection.get_peer_certificate()\n",
    "    except:\n",
    "        certificate = connection.get_peer_certificate()\n",
    "    pem_file = certificate.to_cryptography().public_bytes(serialization.Encoding.PEM)\n",
    "    cert_filename = f\"cert-{host}.cer\"\n",
    "    with open(cert_filename, \"w\") as fout:\n",
    "        fout.write(pem_file.decode('utf8'))\n",
    "    return cert_filename\n",
    "\n",
    "# Extract the hostname\"\n",
    "hostname = urlparse(inference_server_url).netloc\n",
    "os.environ[\"SSL_CERT_FILE\"] = save_srv_cert(hostname, port=443)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2adfea77-1926-4506-89c8-05cf6b4c23c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['REQUESTS_CA_BUNDLE'] = os.environ[\"SSL_CERT_FILE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f57e254-c5d4-44a5-862b-6ff0f2c7e777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl.SSLContext.verify_mode = ssl.VerifyMode.CERT_OPTIONAL\n",
    "os.environ['PYTHONHTTPSVERIFY'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197c6a5-a6ff-49f0-9ab9-9a1a1f268be9",
   "metadata": {},
   "source": [
    "### Preparation for LLM invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a617261-18e8-465e-a400-fc64358929d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efd63f16-9a3b-4c30-bd75-1a2e58d4b51d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":\"pulling manifest\"}\n",
      "{\"status\":\"pulling e8a35b5937a5\",\"digest\":\"sha256:e8a35b5937a5e6d5c35d1f2a15f161e07eefe5e5bb0a3cdd42998ee79b057730\",\"total\":4109853248,\"completed\":4109853248}\n",
      "{\"status\":\"pulling 43070e2d4e53\",\"digest\":\"sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1\",\"total\":11356,\"completed\":11356}\n",
      "{\"status\":\"pulling e6836092461f\",\"digest\":\"sha256:e6836092461ffbb2b06d001fce20697f62bfd759c284ee82b581ef53c55de36e\",\"total\":42,\"completed\":42}\n",
      "{\"status\":\"pulling ed11eda7790d\",\"digest\":\"sha256:ed11eda7790d05b49395598a42b155812b17e263214292f7b87d15e14003d337\",\"total\":30,\"completed\":30}\n",
      "{\"status\":\"pulling f9b1e3196ecf\",\"digest\":\"sha256:f9b1e3196ecfce03ac97468fa0b6d85941fea050c6666c57f5856a8baec6507d\",\"total\":483,\"completed\":483}\n",
      "{\"status\":\"verifying sha256 digest\"}\n",
      "{\"status\":\"writing manifest\"}\n",
      "{\"status\":\"removing any unused layers\"}\n",
      "{\"status\":\"success\"}\n"
     ]
    }
   ],
   "source": [
    "# Ensure there is a model loaded for the LLM instance creation\n",
    "!curl \"https://mistral-7b-instruct-ollama-test.apps.cluster-d975k.d975k.sandbox3026.opentlc.com/api/pull\" -k -H \"Content-Type: application/json\" -d '{\"name\": \"mistral\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b36b2f-c113-40da-8871-1eec8fd3444a",
   "metadata": {},
   "source": [
    "### Create the LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd48774-c314-4468-a33c-a61d4bbf3032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_ollama = Ollama(base_url=inference_server_url,\n",
    "                    model=\"mistral\",\n",
    "                    top_p=0.92,\n",
    "                    temperature=0.01,\n",
    "                    num_predict=512,\n",
    "                    repeat_penalty=1.03,\n",
    "                    callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                   );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915d0e2-8198-4a74-9b94-f6e48f251776",
   "metadata": {},
   "source": [
    "### Create the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "643359f5-e72a-4cd6-9c46-247d8a9f1b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb28d89-887d-4d7a-9633-d1ea4ebbd7c2",
   "metadata": {},
   "source": [
    "### Add some memory for the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454b9d99-8e2b-4f40-b64d-424454da7356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d5e158-c97c-4d36-9c32-a6537af2b688",
   "metadata": {},
   "source": [
    "### Example using conversation verbose mode. This way we can see the memory buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e722f1eb-0e4a-4053-a305-611750d8570e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verbose mode is intentionally set to True so you can see the prompt and the history from the buffer memory\n",
    "conversation = ConversationChain(llm=llm_ollama,\n",
    "                                 prompt=PROMPT,\n",
    "                                 verbose=True,\n",
    "                                 memory=memory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5dd9e0c-a765-48b1-acac-af7865ddfc33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Describe Paris in 100 words or less.\n",
      "AI:\n",
      "[/INST]\n",
      "\u001b[0m\n",
      " Paris, the City of Light, is an iconic global center for art, fashion, gastronomy, and culture. Known for its historic landmarks including the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral, Paris exudes an enchanting allure. Its picturesque streets are filled with charming cafes, elegant boutiques, and world-renowned haute cuisine. Paris' rich history, vibrant energy, and timeless beauty continue to captivate visitors from around the world.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "first_input = \"Describe Paris in 100 words or less.\"\n",
    "conversation.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39419fb0-2a54-4a54-8cd7-dce2260643de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Current conversation:\n",
      "Human: Describe Paris in 100 words or less.\n",
      "AI:  Paris, the City of Light, is an iconic global center for art, fashion, gastronomy, and culture. Known for its historic landmarks including the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral, Paris exudes an enchanting allure. Its picturesque streets are filled with charming cafes, elegant boutiques, and world-renowned haute cuisine. Paris' rich history, vibrant energy, and timeless beauty continue to captivate visitors from around the world.\n",
      "Human: Is there a river?\n",
      "AI:\n",
      "[/INST]\n",
      "\u001b[0m\n",
      " Yes, Paris is home to the beautiful River Seine, which flows right through the heart of the city, adding to its charm and historic significance.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "second_input = \"Is there a river?\"\n",
    "conversation.predict(input=second_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fdcf72-7d06-4655-bd50-342fb38bb658",
   "metadata": {},
   "source": [
    "### Example using non-verbose mode. The output has only the response without the previous chat items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77f48ba4-e878-4335-9a5d-de0e886e88f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation2 = ConversationChain(llm=llm_ollama,\n",
    "                                 prompt=PROMPT,\n",
    "                                 verbose=False,\n",
    "                                 memory=memory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c05dd581-ee42-42ff-a7ff-b789060fc077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's clear the previous conversation first\n",
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c894ca89-9e6b-48f2-a411-f4ad4856fdf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " London, the vibrant capital city of the United Kingdom, is a global cultural melting pot with a rich history. Known for its iconic landmarks like the Tower of London, Buckingham Palace, and the London Eye, it's a city of contrasts, blending modern architecture with ancient history. Its diverse neighborhoods, each with its unique character, offer an array of experiences. From the bustling markets of Camden to the tranquil gardens of Hampstead Heath, London is a city that never sleeps, offering endless opportunities for exploration and discovery."
     ]
    }
   ],
   "source": [
    "first_input = \"Can you describe London in 100 words?\"\n",
    "conversation2.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4adf9be-a725-4574-9046-d31318f5cf92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Absolutely, London is situated on the River Thames, which flows through the heart of the city and is an essential part of its character and history. The river is home to many famous landmarks, including the Houses of Parliament, Tower Bridge, and the iconic London Eye. It's also a popular destination for tourists and locals alike, with numerous boat tours and waterfront activities."
     ]
    }
   ],
   "source": [
    "# This is a follow-up question without context to showcase the conversation memory\n",
    "second_input = \"Is there a river?\"\n",
    "conversation2.predict(input=second_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd645783-f9ac-49fb-b091-87634d914e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
