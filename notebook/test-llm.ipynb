{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ded8507-6f19-4271-b43e-21cf44ab5fae",
   "metadata": {},
   "source": [
    "### Set the Inference server url (replace with your own address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e834566-4cc1-4c94-ba2e-821b9b229892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#inference_server_url = \"http://test-llm10-predictor.test-llm.svc.cluster.local\"\n",
    "inference_server_url = \"https://test-llm10-test-llm.apps.cluster-bjzm6.bjzm6.sandbox2625.opentlc.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca6eda-4709-4d85-bcab-6dc50b20314e",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eba5d7d-10ce-432d-adcc-80458ff26efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain==0.1.9 openai==1.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8839391-a097-4dbc-9a09-b7110a69cabe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install pyOpenSSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae332835-0724-4719-a1f2-80fdec7b03b2",
   "metadata": {},
   "source": [
    "### Extract self signed SSL certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a63b80-fc65-4ab9-9b5e-c89eae7bdb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import OpenSSL\n",
    "import socket\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def save_srv_cert(host, port=443) :\n",
    "    dst = (host, port)\n",
    "    sock = socket.create_connection(dst)\n",
    "    context = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n",
    "    connection = OpenSSL.SSL.Connection(context, sock)\n",
    "    connection.set_tlsext_host_name(host.encode('utf-8'))\n",
    "    connection.set_connect_state()\n",
    "    try:\n",
    "        connection.do_handshake()\n",
    "        certificate = connection.get_peer_certificate()\n",
    "    except:\n",
    "        certificate = connection.get_peer_certificate()\n",
    "    pem_file = certificate.to_cryptography().public_bytes(serialization.Encoding.PEM)\n",
    "    cert_filename = f\"cert-{host}.cer\"\n",
    "    with open(cert_filename, \"w\") as fout:\n",
    "        fout.write(pem_file.decode('utf8'))\n",
    "    return cert_filename\n",
    "\n",
    "# Extract the hostname\"\n",
    "hostname = urlparse(inference_server_url).netloc\n",
    "os.environ[\"SSL_CERT_FILE\"] = save_srv_cert(hostname, port=443)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197c6a5-a6ff-49f0-9ab9-9a1a1f268be9",
   "metadata": {},
   "source": [
    "### Preparation for LLM invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a617261-18e8-465e-a400-fc64358929d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b36b2f-c113-40da-8871-1eec8fd3444a",
   "metadata": {},
   "source": [
    "### Create the LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb8ffe36-1707-421f-976d-f657b2a2387e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM definition\n",
    "llm = VLLMOpenAI(\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base= f\"{inference_server_url}/v1\",\n",
    "    model_name=\"/mnt/models/\",\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915d0e2-8198-4a74-9b94-f6e48f251776",
   "metadata": {},
   "source": [
    "### Create the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643359f5-e72a-4cd6-9c46-247d8a9f1b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb28d89-887d-4d7a-9633-d1ea4ebbd7c2",
   "metadata": {},
   "source": [
    "### Add some memory for the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "454b9d99-8e2b-4f40-b64d-424454da7356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d5e158-c97c-4d36-9c32-a6537af2b688",
   "metadata": {},
   "source": [
    "### Example using conversation verbose mode. This way we can see the memory buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e722f1eb-0e4a-4053-a305-611750d8570e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verbose mode is intentionally set to True so you can see the prompt and the history from the buffer memory\n",
    "conversation = ConversationChain(llm=llm,\n",
    "                                 prompt=PROMPT,\n",
    "                                 verbose=True,\n",
    "                                 memory=memory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5dd9e0c-a765-48b1-acac-af7865ddfc33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Describe Paris in 100 words or less.\n",
      "AI:\n",
      "[/INST]\n",
      "\u001b[0m\n",
      "Paris, the City of Light, is an enchanting metropolis renowned for its iconic landmarks, rich history, and exquisite art scene. Known as the \"City of Love,\" it's home to the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and Montmartre. Parisian streets are filled with charming cafes, patisseries, and boutiques. Its vibrant culture, world-class cuisine, and romantic atmosphere make it a must-visit destination.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "first_input = \"Describe Paris in 100 words or less.\"\n",
    "conversation.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39419fb0-2a54-4a54-8cd7-dce2260643de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Current conversation:\n",
      "Human: Describe Paris in 100 words or less.\n",
      "AI: Paris, the City of Light, is an enchanting metropolis renowned for its iconic landmarks, rich history, and exquisite art scene. Known as the \"City of Love,\" it's home to the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and Montmartre. Parisian streets are filled with charming cafes, patisseries, and boutiques. Its vibrant culture, world-class cuisine, and romantic atmosphere make it a must-visit destination.\n",
      "Human: Is there a river?\n",
      "AI:\n",
      "[/INST]\n",
      "\u001b[0m\n",
      "Yes, Paris is home to the beautiful River Seine, which flows right through its heart and adds to the city's unique charm. The riverbanks are popular spots for leisurely strolls, picnics, and boat rides.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "second_input = \"Is there a river?\"\n",
    "conversation.predict(input=second_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fdcf72-7d06-4655-bd50-342fb38bb658",
   "metadata": {},
   "source": [
    "### Example using non-verbose mode. The output has only the response without the previous chat items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f48ba4-e878-4335-9a5d-de0e886e88f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation2 = ConversationChain(llm=llm,\n",
    "                                 prompt=PROMPT,\n",
    "                                 verbose=False,\n",
    "                                 memory=memory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c05dd581-ee42-42ff-a7ff-b789060fc077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's clear the previous conversation first\n",
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c894ca89-9e6b-48f2-a411-f4ad4856fdf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London, the vibrant capital city of the United Kingdom, is a global cultural hub teeming with history, art, and modern innovation. Known for iconic landmarks like the Tower of London, Buckingham Palace, and the British Museum, it's a city rich in heritage. The River Thames winds through its heart, offering scenic views and transportation via the iconic red double-decker buses and the Tube. London's diverse neighborhoods, from Soho's bustling streets to the tranquil Regent's Park, showcase its multicultural population and world-class cuisine. Its energy and diversity make it an unforgettable destination."
     ]
    }
   ],
   "source": [
    "first_input = \"Can you describe London in 100 words?\"\n",
    "conversation2.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4adf9be-a725-4574-9046-d31318f5cf92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the River Thames runs through London. It's an essential part of the city's landscape and history, providing scenic views and transportation via various watercraft."
     ]
    }
   ],
   "source": [
    "# This is a follow-up question without context to showcase the conversation memory\n",
    "second_input = \"Is there a river?\"\n",
    "conversation2.predict(input=second_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd645783-f9ac-49fb-b091-87634d914e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
